{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b768f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../DP/Env\"))\n",
    "sys.path.append(os.path.abspath(\"../DP/Algorithms/\"))\n",
    "sys.path.append(os.path.abspath(\"../Instances\"))\n",
    "\n",
    "\n",
    "from Knapsack import KnapsackEnv\n",
    "from InsKnapsack import generate_knapsack_instance\n",
    "\n",
    "from value_iteration import value_iteration\n",
    "from policy_evaluation import policy_evaluation\n",
    "from policy_iteration import policy_iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b71ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = [15, 15, 5, 2, 1, 12, 7, 2, 6, 8, 1, 10, 11, 5, 5]\n",
      "values  = [5, 6, 5, 3, 2, 9, 10, 10, 9, 8, 8, 3, 7, 4, 1]\n",
      "capacity = 26\n"
     ]
    }
   ],
   "source": [
    "weights, values, capacity = generate_knapsack_instance(\n",
    "    n=15,\n",
    "    w_min=1,  w_max=15,\n",
    "    v_min=1,  v_max=10,\n",
    "    capacity_ratio=0.25,\n",
    ")\n",
    "\n",
    "print(\"weights =\", weights)\n",
    "print(\"values  =\", values)\n",
    "print(\"capacity =\", capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dd70f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnapsackEnv(#_Objetos = 15, Capacidad = 26, #_Estados = 432)\n"
     ]
    }
   ],
   "source": [
    "env = KnapsackEnv(weights, values, capacity)\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06db701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construye un diccionario «política» que asigna a cada estado s\n",
    "# (tupla (i, c) = índice del objeto, capacidad restante)\n",
    "# la acción 'take' cuando sea LEGAL tomar el objeto,\n",
    "# y 'skip' en caso contrario.\n",
    "\n",
    "propose_policy = {\n",
    "    s: ('take' if 'take' in env.actions(s) else 'skip')\n",
    "    for s in env.state_space()\n",
    "}\n",
    "\n",
    "policy = propose_policy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4ddaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetos seleccionados:\n",
      "  • Obj  0: peso=15, valor=5\n",
      "  • Obj  2: peso=5, valor=5\n",
      "  • Obj  3: peso=2, valor=3\n",
      "  • Obj  4: peso=1, valor=2\n",
      "  • Obj  7: peso=2, valor=10\n",
      "  • Obj 10: peso=1, valor=8\n",
      "\n",
      "Tiempo de ejecución: 0.001839 s\n",
      "FO (valor total):    33\n",
      "Presupuesto usado:   26/26\n"
     ]
    }
   ],
   "source": [
    "# 1. Cronometrar todo el proceso\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# 2. Evaluar la política (valor esperado de cada estado)\n",
    "V = policy_evaluation(env, propose_policy)\n",
    "\n",
    "# 3. Simular una ejecución para saber qué objetos se toman realmente\n",
    "objs_tomados   = []      # índices de objetos\n",
    "peso_acumulado = 0\n",
    "\n",
    "state = env.reset()      # (i, c) = (0, capacidad)\n",
    "done  = False\n",
    "while not done:\n",
    "    action = policy[state]\n",
    "    if action == \"take\":\n",
    "        idx_obj = state[0]                # i = índice del objeto actual\n",
    "        objs_tomados.append(idx_obj)\n",
    "        peso_acumulado += env.weights[idx_obj]\n",
    "    state, _, done = env.step(action)\n",
    "\n",
    "FO  = env.total_reward                    # valor total conseguido\n",
    "dt  = time.perf_counter() - t0            # segundos de ejecución\n",
    "\n",
    "# 4. Mostrar resultados\n",
    "\n",
    "print(\"Objetos seleccionados:\")\n",
    "for idx in objs_tomados:\n",
    "    w, v = env.weights[idx], env.values[idx]\n",
    "    print(f\"  • Obj {idx:>2}: peso={w}, valor={v}\")\n",
    "    \n",
    "print(f\"\\nTiempo de ejecución: {dt:.6f} s\")\n",
    "print(f\"FO (valor total):    {FO}\")\n",
    "print(f\"Presupuesto usado:   {peso_acumulado}/{env.capacity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9241c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetos seleccionados:\n",
      "  • Obj  3: peso=2, valor=3\n",
      "  • Obj  6: peso=7, valor=10\n",
      "  • Obj  7: peso=2, valor=10\n",
      "  • Obj  8: peso=6, valor=9\n",
      "  • Obj  9: peso=8, valor=8\n",
      "  • Obj 10: peso=1, valor=8\n",
      "\n",
      "Tiempo de ejecución: 0.009803 s\n",
      "FO (valor total):    48\n",
      "Presupuesto usado:   26/26\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 1.  Obtener la política óptima y cronometrar el proceso completo\n",
    "# -------------------------------------------------------------------\n",
    "t0 = time.perf_counter()\n",
    "star_policy, V_star = policy_iteration(env, policy)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2.  Recorrer el episodio con la política óptima para saber qué toma\n",
    "# -------------------------------------------------------------------\n",
    "state      = env.reset()          # (i, c) = (0, capacidad)\n",
    "chosen     = []                   # índices de los objetos tomados\n",
    "peso_tot   = 0\n",
    "valor_tot  = 0\n",
    "\n",
    "while not env.is_terminal(state):\n",
    "    a = star_policy[state]\n",
    "    if a == \"take\":\n",
    "        idx = state[0]                  # índice del objeto actual\n",
    "        chosen.append(idx)\n",
    "        peso_tot  += env.weights[idx]\n",
    "        valor_tot += env.values[idx]\n",
    "    state, _ = env.sim_step(state, a)\n",
    "    \n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3.  Mostrar resultados en el formato requerido\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Objetos seleccionados:\")\n",
    "for idx in chosen:\n",
    "    w, v = env.weights[idx], env.values[idx]\n",
    "    print(f\"  • Obj {idx:>2}: peso={w}, valor={v}\")\n",
    "\n",
    "print(f\"\\nTiempo de ejecución: {elapsed:.6f} s\")\n",
    "\n",
    "# FO = retorno total; equivale a V_opt[(0, env.capacity)] si gamma=1\n",
    "print(f\"FO (valor total):    {valor_tot}\")\n",
    "\n",
    "print(f\"Presupuesto usado:   {peso_tot}/{env.capacity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d28864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetos seleccionados:\n",
      "  • Obj  3: peso=2, valor=3\n",
      "  • Obj  6: peso=7, valor=10\n",
      "  • Obj  7: peso=2, valor=10\n",
      "  • Obj  8: peso=6, valor=9\n",
      "  • Obj  9: peso=8, valor=8\n",
      "  • Obj 10: peso=1, valor=8\n",
      "\n",
      "Tiempo de ejecución: 0.003353 s\n",
      "FO (valor total):    48\n",
      "Presupuesto usado:   26/26\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 1.  Obtener la política óptima y cronometrar el proceso completo\n",
    "# -------------------------------------------------------------------\n",
    "t0 = time.perf_counter()\n",
    "opt_policy, V_opt = value_iteration(env)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2.  Recorrer el episodio con la política óptima para saber qué toma\n",
    "# -------------------------------------------------------------------\n",
    "state      = env.reset()          # (i, c) = (0, capacidad)\n",
    "chosen     = []                   # índices de los objetos tomados\n",
    "peso_tot   = 0\n",
    "valor_tot  = 0\n",
    "\n",
    "while not env.is_terminal(state):\n",
    "    a = opt_policy[state]\n",
    "    if a == \"take\":\n",
    "        idx = state[0]                  # índice del objeto actual\n",
    "        chosen.append(idx)\n",
    "        peso_tot  += env.weights[idx]\n",
    "        valor_tot += env.values[idx]\n",
    "    state, _ = env.sim_step(state, a)\n",
    "\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3.  Mostrar resultados en el formato requerido\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Objetos seleccionados:\")\n",
    "for idx in chosen:\n",
    "    w, v = env.weights[idx], env.values[idx]\n",
    "    print(f\"  • Obj {idx:>2}: peso={w}, valor={v}\")\n",
    "\n",
    "print(f\"\\nTiempo de ejecución: {elapsed:.6f} s\")\n",
    "\n",
    "# FO = retorno total; equivale a V_opt[(0, env.capacity)] si gamma=1\n",
    "print(f\"FO (valor total):    {valor_tot}\")\n",
    "\n",
    "print(f\"Presupuesto usado:   {peso_tot}/{env.capacity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598bea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
