{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d358bf1",
   "metadata": {},
   "source": [
    "# Programación Dinámica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd59104",
   "metadata": {},
   "source": [
    "La **Programación Dinámica (PD)** es una familia de métodos que resuelve procesos de decisión secuenciales (deterministas o estocásticos) cuando el modelo del entorno se conoce por completo:\n",
    "\n",
    "* **Probabilidades de transición** $P(s' \\mid s, a)$\n",
    "\n",
    "  * $1$ en el caso determinista.\n",
    "  * Una distribución de probabilidad sobre los posibles sucesores $s'$ en el caso estocástico.\n",
    "* **Recompensas inmediatas esperadas** $R(s, a, s')$.\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $S$: conjunto de estados.\n",
    "* $A$: conjunto de acciones.\n",
    "* $P(s' \\mid s, a)$: probabilidad de pasar de $s$ a $s'$ al ejecutar $a$.\n",
    "* $R(s, a, s')$: recompensa inmediata esperada al transitar de $s$ a $s'$ con la acción $a$.\n",
    "* $\\gamma$: factor de descuento $(0 \\le \\gamma \\le 1)$ que pondera las recompensas futuras.\n",
    "\n",
    "El objetivo es hallar una política que maximice la recompensa acumulada esperada. Para ello se resuelven recursivamente las **ecuaciones de Bellman**.\n",
    "\n",
    "* **Ecuaciones de Bellman**:\n",
    "\n",
    "  $$\n",
    "  v_\\pi(s) \\;=\\; \\sum_{a} \\pi(a \\mid s) \\sum_{s'} P(s' \\mid s, a)\\,\\bigl[R(s, a, s') + \\gamma\\,v_\\pi(s')\\bigr].\n",
    "  $$\n",
    "* **Recompensa acumulada**: $v_\\pi(s)$ es el valor esperado al seguir la política $\\pi$ desde el estado $s$.\n",
    "* **Objetivo**: encontrar la política óptima $\\pi^{*}$ tal que\n",
    "\n",
    "  $$\n",
    "  v_{\\pi^{*}}(s) \\;\\ge\\; v_\\pi(s), \\qquad \\forall\\,s \\in S,\\;\\forall\\,\\pi.\n",
    "  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae3603",
   "metadata": {},
   "source": [
    "## Ejemplo — MinObras\n",
    "\n",
    "El Ministerio de Transporte (MinTransporte) cuenta con un presupuesto de **100 millones de pesos** para ejecutar obras de infraestructura vial, con el fin de generar desarrollo en Bogotá. D.C.\n",
    "\n",
    "MinTransporte le va a proporcionar datos que contiene información sobre:\n",
    "\n",
    "- **Costo de ejecución** de cada proyecto (en millones de pesos)\n",
    "- **Número de empleos generados** (en miles)\n",
    "- **Ubicación geográfica** del proyecto (latitud y longitud)\n",
    "\n",
    "El objetivo del Ministerio es **maximizar la cantidad total de empleos generados**, respetando el límite presupuestal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4057a",
   "metadata": {},
   "source": [
    "**Datos de entrada**\n",
    "\n",
    "| ID | Ciudad       | Costo ejecución (\\$c\\_i\\$) \\[millones] | Empleos generados (\\$e\\_i\\$) \\[miles] | Latitud   | Longitud   |\n",
    "| -- | ------------ | -------------------------------------- | ------------------------------------- | --------- | ---------- |\n",
    "| 1  | Bogotá       | 9                                      | 13                                    | 4.710989  | -74.072090 |\n",
    "| 2  | Medellín     | 3                                      | 6                                     | 6.244203  | -75.581215 |\n",
    "| 3  | Cartagena    | 1                                      | 3                                     | 10.391049 | -75.479426 |\n",
    "| 4  | Barranquilla | 6                                      | 9                                     | 10.963889 | -74.796387 |\n",
    "| 5  | Cali         | 10                                     | 15                                    | 3.451647  | -76.531985 |\n",
    "| 6  | Palomino     | 3                                      | 5                                     | 11.259400 | -73.569200 |\n",
    "\n",
    "<br>\n",
    "<img src=\"assets/proyectos_colombia_map.png\" alt=\"Proyectos por Ciudad en Colombia\" width=\"500\"/>\n",
    "\n",
    "**Parámetros del modelo**\n",
    "\n",
    "- Conjunto de obras disponibles:  \n",
    "  $O = \\{1, 2, 3, 4, 5, 6\\}$\n",
    "\n",
    "- Costo de ejecución de cada obra (en millones):  \n",
    "  $c = \\{c_1 = 9,\\; c_2 = 3,\\; c_3 = 1,\\; c_4 = 6,\\; c_5 = 10,\\; c_6 = 3\\}$\n",
    "\n",
    "- Empleos generados por cada obra (en miles):  \n",
    "  $e = \\{e_1 = 13,\\; e_2 = 6,\\; e_3 = 3,\\; e_4 = 9,\\; e_5 = 15,\\; e_6 = 5\\}$\n",
    "\n",
    "- Presupuesto total disponible:  \n",
    "  $p = 20$\n",
    "\n",
    "**Objetivo del problema**\n",
    "\n",
    "Maximizar la cantidad total de empleos generados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ed2ae",
   "metadata": {},
   "source": [
    "### Modelo - Programación Dinámica\n",
    "\n",
    "#### 1. Estados (¿en qué situación estamos?)\n",
    "\n",
    "* **Qué es un estado:** un par **(k, b)**.\n",
    "\n",
    "  * **k** = número de la **próxima obra** que falta por decidir.\n",
    "    *En este ejemplo las obras están numeradas del 1 al 6, así que k puede valer 1, 2, 3, 4, 5 o 6. Cuando k pasa a 7 significa que ya evaluamos todas y hemos llegado al final.*\n",
    "  * **b** = **presupuesto que queda** en millones (puede ser 0 … 20).\n",
    "\n",
    "> Ejemplo: el estado **(3, 14)** se lee así:\n",
    "> “La siguiente obra por estudiar es la # 3 y aún contamos con 14 millones”.\n",
    "\n",
    "#### 2. Acciones (las decisiones posibles)\n",
    "\n",
    "En cualquier estado con **k (obra) ≤ 6** tienes dos opciones:\n",
    "\n",
    "1. **Ejecutar** la obra k\n",
    "\n",
    "   * Solo si su costo **cₖ** no excede el presupuesto disponible *b*.\n",
    "   * Costos reales: c = {9, 3, 1, 6, 10, 3} millones.\n",
    "\n",
    "2. **Omitir** la obra k\n",
    "\n",
    "   * Siempre posible; simplemente pasas a la siguiente obra sin gastar nada.\n",
    "\n",
    "Cuando **k = 7** ya no hay acciones: se terminó.\n",
    "\n",
    "#### 3. Transición (cómo cambia el estado y cuántos empleos ganamos)\n",
    "\n",
    "Las reglas son **deterministas** (sin azar):\n",
    "\n",
    "| Acción tomada en (k, b) | Nuevo estado    | Recompensa inmediata |\n",
    "| ----------------------- | --------------- | -------------------- |\n",
    "| **Ejecutar**            | (k + 1, b – cₖ) | eₖ miles de empleos  |\n",
    "| **Omitir**              | (k + 1, b)      | 0                    |\n",
    "\n",
    "Los empleos reales son e = {13, 6, 3, 9, 15, 5} (miles).\n",
    "\n",
    "> Ejemplo: Estás en (2, 11).\n",
    ">\n",
    "> * Si ejecutas la obra 2 (cuesta 3), pasarás a (3, 8) y obtendrás **6 miles de empleos**.\n",
    "> * Si la omites, pasarás a (3, 11) y obtendrás **0 empleos** en ese paso.\n",
    "\n",
    "#### 4. Recompensa (lo que te importa maximizar)\n",
    "\n",
    "* **Ejecutar** obra k ⇒ ganas eₖ miles de empleos.\n",
    "* **Omitir** ⇒ ganas 0 en ese momento.\n",
    "\n",
    "La **suma** de recompensas a lo largo de los 6 pasos es el **total de empleos** que logres crear.\n",
    "\n",
    "#### 5. Factor de descuento γ\n",
    "\n",
    "* Usamos **γ = 1**.\n",
    "* Razón: el problema dura solo 6 decisiones y **no preferimos** empleos “prontos” frente a “tardíos”. Cada empleo vale lo mismo sin importar cuándo se consiga dentro de la secuencia.\n",
    "\n",
    "#### 6. Estado inicial\n",
    "\n",
    "* Arrancamos siempre en **(1, 20)**:\n",
    "\n",
    "  > “Aún no hemos decidido ninguna obra y disponemos de los 20 millones completos”.\n",
    "\n",
    "#### 7. Estados terminales\n",
    "\n",
    "* Cualquier estado con **k = 7** (hemos avanzado más allá de la obra 6).\n",
    "* En ese punto ya no quedan obras por evaluar, el presupuesto que sobre no se usa y se concluye.\n",
    "\n",
    "#### Resumen:\n",
    "\n",
    "1. Empiezas con la obra 1 y 20 millones.\n",
    "2. Para cada obra decides “hacerla” (si alcanza la plata) o “saltarla”.\n",
    "3. Si la haces, restas su costo del presupuesto y sumas sus empleos.\n",
    "4. Avanzas secuencialmente hasta la obra 6. (última).\n",
    "5. Al terminar, tu objetivo es que la **suma total de empleos** sea la mayor posible sin pasarte del presupuesto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452fe5d3",
   "metadata": {},
   "source": [
    "| **Símbolo**                          | **Definición (problema de asignación de obras)**                                                                                                                                                 | **Comentarios**                                                                                                    |\n",
    "| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Estados $\\mathcal{S}$**            | Par ordenado $s = (i,b)$ donde:<br>• $i \\in \\{1,\\dots,n\\}$ es el índice de la **próxima** obra por decidir (con (n = O     )).<br>• $b \\in \\{1,\\dots,p\\}$ es el **presupuesto restante** (en millones). | Contiene toda la información relevante: cuántas obras faltan por evaluar y cuánto presupuesto queda.               |\n",
    "| **Acciones $\\mathcal{A}(s)$**        | Para $i < n$:<br>• **Ejecutar** la obra $i$ (solo si $c_i \\le b$).<br>• **Omitir** la obra $i$.<br>Para $i = n$ no hay acciones (estado terminal).           | Al **ejecutar** se avanza al siguiente índice y se descuenta su costo; al **omitir** solo se avanza el índice.     |\n",
    "| **Transición $p(s',r \\mid s,a)$**    | **Determinista**. Desde $(i,b)$:<br>– Si **ejecutar**: $s' = (i+1,\\,b-c_i)$, recompensa $r = e_i$.<br>– Si **omitir**: $s' = (i+1,\\,b)$, recompensa $r = 0$. | No existe incertidumbre: las transiciones y recompensas quedan completamente determinadas por la acción.           |\n",
    "| **Recompensa $\\mathcal{R}(s,a)$**    | Empleos inmediatos generados por la obra si se ejecuta; $0$ si se omite.                                                                                     | La **suma total de recompensas** a lo largo del episodio equivale al número total de empleos obtenidos (en miles). |\n",
    "| **Factor de descuento $\\gamma$**     | $\\gamma = 1$                                                                                                                                                 | El horizonte es finito (máximo $n$ decisiones) y no se prefiere empleos “tempranos” sobre “tardíos”.               |\n",
    "| **Distribución inicial $p_0(s)$**    | Único estado inicial $s_0 = (1,p)$.                                                                                                                          | Se parte con ninguna obra seleccionada y el presupuesto total disponible.                                          |\n",
    "| **Estados terminales $\\mathcal{T}$** | Todos los estados con $i = n$.                                                                                                                               | Tras evaluar las $n$ obras ya no quedan decisiones; el episodio concluye.                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f7dc4",
   "metadata": {},
   "source": [
    "## Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b4cf1",
   "metadata": {},
   "source": [
    "```text\n",
    "# Calcula Vπ para una política fija π\n",
    "# Entradas:\n",
    "#   S          : conjunto de estados\n",
    "#   π(s)       : política dada (acción para cada s)\n",
    "#   p(s',r|s,a): modelo de transición y recompensa\n",
    "#   γ          : factor de descuento (0 ≤ γ ≤ 1)\n",
    "#   θ          : umbral de convergencia\n",
    "# Salida:\n",
    "#   Vπ(s)      : valor esperado para cada estado bajo π\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Inicialización\n",
    "V(s) ← 0  para todo s ∈ S\n",
    "\n",
    "# Evaluación iterativa\n",
    "repetir\n",
    "    Δ ← 0\n",
    "    para cada estado s ∈ S:\n",
    "        v ← V(s)                                    # valor anterior\n",
    "        a ← π(s)                                    # acción dictada por la política\n",
    "        V(s) ← Σ_{s',r} p(s',r | s,a) · [ r + γ · V(s') ]\n",
    "        Δ ← max(Δ, |v − V(s)|)\n",
    "hasta que Δ < θ\n",
    "\n",
    "return V\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c232eb",
   "metadata": {},
   "source": [
    "### Definición de política\n",
    "\n",
    "En cada paso del proceso secuencial se decide **tomar** la obra actual si el presupuesto lo permite, o **saltar** de lo contrario.\n",
    "La política determinista se define como:\n",
    "\n",
    "$$\n",
    "\\pi(i, b) =\n",
    "\\begin{cases}\n",
    "\\text{tomar}, & c_i \\leq b \\\\ \n",
    "\\text{saltar}, & \\text{en otro caso}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "donde:  \n",
    "- $i$ es el índice de la **obra evaluada** (del 1 al 7, siendo 7 el estado final sin obras por evaluar).  \n",
    "- $b$ es el **presupuesto restante** (en millones).\n",
    "\n",
    "#### Espacio de estados\n",
    "\n",
    "- Presupuesto total:  $p = 20$\n",
    "- Cada estado se representa como una tupla:  $(i, b)$\n",
    "  con:  \n",
    "    -  $i \\in \\{1, 2, 3, 4, 5, 6, 7\\}$\n",
    "    - $b \\in \\{0, 1, 2, \\dots, 20\\}$\n",
    "- Número total de estados:  $7 \\times 21 = 147$\n",
    "\n",
    "#### Ejemplos de la política $\\pi(s)$\n",
    "\n",
    "| Ejemplo | Estado $(i, b)$ | Descripción                                                   | Costo $c_i$ | ¿$c_i \\le b$? | Acción $\\pi(s)$ |\n",
    "|---------|-----------------|---------------------------------------------------------------|-------------|---------------|-----------------|\n",
    "| 1       | $(1, 20)$       | Primera obra, 20 millones disponibles                         | $c_1 = 9$   | Sí            | **tomar**       |\n",
    "| 2       | $(2, 11)$       | Tras tomar la obra 1, quedan 11 millones                      | $c_2 = 3$   | Sí            | **tomar**       |\n",
    "| 3       | $(3, 8)$        | Tras tomar las obras 1 y 2, quedan 8 millones                 | $c_3 = 1$   | Sí            | **tomar**       |\n",
    "| 4       | $(5, 1)$        | Tras tomar las obras 1–4, queda 1 millón; se evalúa la obra 5 | $c_5 = 10$  | No            | **saltar**      |\n",
    "| 5       | $(6, 1)$        | Se evalúa la obra 6 con 1 millón restante                     | $c_6 = 3$   | No            | **saltar**      |\n",
    "\n",
    "#### Trayectoria paso a paso\n",
    "\n",
    "| Paso | Estado $(i,b)$ antes de decidir | ¿Se toma? | Nuevo presupuesto $b'$ | Empleos obtenidos en el paso |\n",
    "|------|---------------------------------|-----------|------------------------|------------------------------|\n",
    "| 1    | $(1,20)$                        | Sí ($9\\le20$)  | $20-9 = 11$ | 13 |\n",
    "| 2    | $(2,11)$                        | Sí ($3\\le11$)  | $11-3 = 8$  | 6  |\n",
    "| 3    | $(3,8)$                         | Sí ($1\\le8$)   | $8-1 = 7$   | 3  |\n",
    "| 4    | $(4,7)$                         | Sí ($6\\le7$)   | $7-6 = 1$   | 9  |\n",
    "| 5    | $(5,1)$                         | No ($10>1$)    | $1$         | 0  |\n",
    "| 6    | $(6,1)$                         | No ($3>1$)     | $1$         | 0  |\n",
    "| —    | **Final $(7,1)$**               | —              | —           | —  |\n",
    "\n",
    "*Resultados de la política*\n",
    "\n",
    "- **Obras seleccionadas:** 1, 2, 3 y 4  \n",
    "- **Costo total:** 9 + 3 + 1 + 6 = 19 millones  \n",
    "- **Empleos generados:** 13 + 6 + 3 + 9 = **31 miles**  \n",
    "- **Presupuesto sin usar:** 1 millón\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d95ef",
   "metadata": {},
   "source": [
    "### Pseudocódigo\n",
    "\n",
    "Este algoritmo calcula de forma iterativa el valor esperado de cada estado bajo una política dada $\\pi$. El procedimiento estima la función de valor $V(s)$ para todos los estados $s \\in \\mathcal{S}$ hasta que la aproximación sea suficientemente precisa.\n",
    "\n",
    "##### Entradas\n",
    "- $\\pi$: política fija que se desea evaluar\n",
    "- $\\mathcal{S}$: conjunto de todos los estados posibles\n",
    "- $p(s', r \\mid s, a)$: probabilidad de transición y recompensa al ejecutar la acción $a$ en el estado $s$\n",
    "- $\\gamma$: factor de descuento ($0 \\leq \\gamma < 1$)\n",
    "- $\\theta$: umbral de convergencia (pequeño número positivo)\n",
    "\n",
    "##### Inicialización\n",
    "- Se asigna $V(s) = 0$ para todo $s \\in \\mathcal{S}$\n",
    "\n",
    "##### Algoritmo\n",
    "Se repiten las siguientes actualizaciones hasta que los cambios en los valores de los estados sean menores que el umbral $\\theta$:\n",
    "\n",
    "1. Inicializar $\\Delta \\leftarrow 0$  \n",
    "2. Para cada estado $s \\in \\mathcal{S}$:\n",
    "    - Guardar el valor actual: $v \\leftarrow V(s)$  \n",
    "    - Actualizar $V(s)$ según la política $\\pi$ y el modelo del entorno:  \n",
    "      $$\n",
    "      V(s) \\leftarrow \\sum_a \\pi(a \\mid s) \\sum_{s', r} p(s', r \\mid s, a)\\,\\left[ r + \\gamma V(s') \\right]\n",
    "      $$\n",
    "    - Actualizar la diferencia máxima:  \n",
    "      $$\n",
    "      \\Delta \\leftarrow \\max\\left(\\Delta,\\; |v - V(s)|\\right)\n",
    "      $$\n",
    "\n",
    "3. Repetir hasta que $\\Delta < \\theta$\n",
    "\n",
    "##### Salida\n",
    "- Se retorna la función $V$ que aproxima el valor esperado de cada estado bajo la política $\\pi$:  \n",
    "  $$\n",
    "  V \\approx v_\\pi\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a6ea5",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "Se ilustra el cálculo del valor esperado $V(s)$ de cada estado bajo la política voraz: *“tomar la obra si su costo cabe en el presupuesto restante; de lo contrario, saltarla”.*  Se usa $\\gamma = 1$ (sin descuento) y evaluación iterativa con umbral $\\theta = 0{.}01$.\n",
    "\n",
    "**Iteración 0 – inicialización**\n",
    "\n",
    "$V(s) = 0$ para todo estado $(i,b)$.\n",
    "\n",
    "**Iteración 1**\n",
    "\n",
    "Se recorre la trayectoria que genera la política (presupuesto inicial 20 M):\n",
    "\n",
    "| Paso | Estado $s$ | Acción $\\pi(s)$ | Recompensa $r$ | Siguiente estado $s'$ | $V_{\\text{nuevo}}(s)=r+V(s')$ |\n",
    "|------|------------|-----------------|----------------|-----------------------|--------------------------------|\n",
    "| 0 | $(1,\\,20)$ | tomar (obra 1) | 13 | $(2,\\,11)$ | 13 |\n",
    "| 1 | $(2,\\,11)$ | tomar (obra 2) | 6  | $(3,\\,8)$  | 6  |\n",
    "| 2 | $(3,\\,8)$  | tomar (obra 3) | 3  | $(4,\\,7)$  | 3  |\n",
    "| 3 | $(4,\\,7)$  | tomar (obra 4) | 9  | $(5,\\,1)$  | 9  |\n",
    "| 4 | $(5,\\,1)$  | saltar (obra 5) | 0 | $(6,\\,1)$  | 0  |\n",
    "| 5 | $(6,\\,1)$  | saltar (obra 6) | 0 | $(7,\\,1)$ | 0 |\n",
    "\n",
    "* Cualquier $(7,b)$ es terminal ⇒ $V=0$.\n",
    "\n",
    "*Valores tras la primera pasada*  \n",
    "    - $V(6,1)=0$ <br>\n",
    "    - $V(5,1)=0$ <br>\n",
    "    - $V(4,7)=9$ <br>\n",
    "    - $V(3,8)=3$ <br>\n",
    "    - $V(2,11)=6$ <br>\n",
    "    - $V(1,20)=13$ <br>\n",
    "\n",
    "**Iteración 2 – propagación detallada**\n",
    "\n",
    "Se actualiza nuevamente cada estado *usando ya los valores recién calculados* de su sucesor:\n",
    "\n",
    "| Paso (de atrás hacia delante) | Estado $s$ | $r$ | $V\\_{\\text{ant}}(s')$ | Cálculo $r+V(s')$ | $V\\_{\\text{nuevo}}(s)$ |\n",
    "|-------------------------------|------------|-----|----------------------|-------------------|------------------------|\n",
    "| 5 | $(6,1)$ | 0 | $V(7,1)=0$ | $0+0$ | *0* (sin cambio) |\n",
    "| 4 | $(5,1)$ | 0 | $V(6,1)=0$ | $0+0$ | *0* (sin cambio) |\n",
    "| 3 | $(4,7)$ | 9 | $V(5,1)=0$ | $9+0$ | *9* (sin cambio) |\n",
    "| 2 | $(3,8)$ | 3 | $V(4,7)=9$ | $3+9$ | *12* (sube de 3) |\n",
    "| 1 | $(2,11)$| 6 | $V(3,8)=12$| $6+12$| *18* (sube de 6) |\n",
    "| 0 | $(1,20)$|13 | $V(2,11)=18$|$13+18$| *31* (sube de 13)|\n",
    "\n",
    "*Valores tras la segunda pasada* \n",
    "    - $V(6,1)=0$ <br>\n",
    "    - $V(5,1)=0$ <br>\n",
    "    - $V(4,7)=9$ <br>\n",
    "    - $V(3,8)=12$ <br>\n",
    "    - $V(2,11)=18$ <br>\n",
    "    - $V(1,20)=31$ <br>\n",
    "\n",
    "**Iteración 3**\n",
    "\n",
    "Al repetir los cálculos se obtienen exactamente los mismos valores ⇒ $\\Delta=0<\\theta$.  \n",
    "*Convergencia alcanzada.*\n",
    "\n",
    "**Valor resultante por estado visitado**\n",
    "\n",
    "| Estado $s$ | $V(s)$ (miles de empleos) |\n",
    "|------------|---------------------------|\n",
    "| $(1,\\,20)$ | **31** |\n",
    "| $(2,\\,11)$ | 18 |\n",
    "| $(3,\\,8)$  | 12 |\n",
    "| $(4,\\,7)$  | 9 |\n",
    "| $(5,\\,1)$  | 0 |\n",
    "| $(6,\\,1)$  | 0 |\n",
    "| $(7,\\,b)$  | 0 |\n",
    "\n",
    "Desde el estado inicial la política produce un *valor esperado de 31 000 empleos*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c40028",
   "metadata": {},
   "source": [
    "### Análisis\n",
    "\n",
    "**Qué representa el tablero**\n",
    "\n",
    "* Es un mapa de calor de 7 filas × 21 columnas.  \n",
    "  * Cada **fila** (eje vertical) indica la obra que se está pensando construir: $i = 1, 2, \\dots, 7$.  \n",
    "  * Cada **columna** (eje horizontal) indica el dinero que queda: $b = 0, 1, \\dots, 20$ millones.  \n",
    "\n",
    "**Cómo leer los colores**\n",
    "\n",
    "* Cada cuadrito muestra el valor esperado $V(s)$ (empleos en miles) si empezaras en ese estado $s = (i, b)$ y aplicaras la regla:  \n",
    "  > *“Toma la obra si su costo cabe; si no, sáltala”*  \n",
    "* **Verde claro** ⇒ pocos empleos futuros.  \n",
    "* **Verde oscuro** ⇒ muchos empleos futuros.  \n",
    "\n",
    "**Los números dentro de cada celda**\n",
    "\n",
    "* El número impreso es el $V(s)$ exacto.  \n",
    "* Ejemplo: $31$ en la esquina superior‑derecha significa *31 000 empleos* si arrancas en la obra 1 con 20 millones.  \n",
    "\n",
    "**La ruta roja con círculos**\n",
    "\n",
    "1. Empieza en $(1,\\,20)$ (arriba a la derecha).  \n",
    "2. Desciende por los círculos $(2,\\,11)$, $(3,\\,8)$, $(4,\\,7)$.  \n",
    "3. Con solo 1 millón restante, la regla **salta** las obras 5 y 6 → $(5,\\,1)$ y $(6,\\,1)$.  \n",
    "4. Llega a $(7,\\,1)$, un estado terminal (sin obras pendientes).  \n",
    "\n",
    "Esa línea muestra exactamente las decisiones que toma la política con tu presupuesto inicial.  \n",
    "\n",
    "**Resultado de la política en esa trayectoria**\n",
    "\n",
    "* **Empleos logrados**: 31 000.  \n",
    "* **Obras construidas**: 1, 2, 3 y 4.  \n",
    "* **Dinero gastado**: 19 millones (queda 1 millón sin usar).  \n",
    "\n",
    "**¿Por qué hay valores en celdas que no se pisan?**\n",
    "\n",
    "El algoritmo también calcula $V(s)$ para estados que nunca visitas.  \n",
    "Sirve para saber *qué pasaría* si comenzaras con otro dinero o si hubieras tomado/omitido obras distintas.  \n",
    "\n",
    "**Idea clave**\n",
    "\n",
    "El gráfico muestra cuánto valen todas las combinaciones obra‑presupuesto y cómo se desplaza la política voraz para sacar la mayor cantidad de empleos posible sin rebasar los 20 millones.  \n",
    "\n",
    "<br>\n",
    "<img src=\"assets/policy_evaluation_v.png\" alt=\"Policy Evaluation V\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab66944",
   "metadata": {},
   "source": [
    "**Qué muestra el diagrama**\n",
    "\n",
    "Es un grafo dirigido que contiene *todos* los estados posibles $(i,b)$ y *todas* las transiciones legales entre ellos.\n",
    "Cada nodo es un estado; cada flecha indica cómo cambia el estado al decidir *tomar* o *saltar* la obra actual.\n",
    "\n",
    "**Cómo están acomodados los nodos**\n",
    "\n",
    "* Las columnas van de izquierda a derecha con el índice de obra $i$: primera columna $i{=}1$, segunda $i{=}2$ … hasta $i{=}7$.\n",
    "* Dentro de cada columna los nodos se apilan por el presupuesto restante $b$; arriba está $b{=}20$ y abajo $b{=}0$.\n",
    "* Así, moverse una columna a la derecha siempre significa “pasar a la siguiente obra”.\n",
    "\n",
    "**Colores de los nodos**\n",
    "\n",
    "* **Verde** = estados por los que realmente pasa la política cuando ejecuta las obras 1–4.\n",
    "* **Azul** = estados de “saltar” (obras 5 y 6) que también son visitados.\n",
    "* **Gris claro** = todos los demás estados teóricos que *existen* pero la política nunca toca.\n",
    "\n",
    "**Grosor de las flechas**\n",
    "\n",
    "* Las flechas finas muestran *todas* las transiciones posibles si uno aplicara la regla en cada estado.\n",
    "* La **línea negra gruesa** marca la ruta exacta seguida desde el estado inicial $(1,20)$ hasta el final $(7,1)$.\n",
    "\n",
    "**Cómo leer la ruta resaltada**\n",
    "\n",
    "1. Arranca en el nodo verde superior de la primera columna $(1,20)$.\n",
    "2. La política decide *tomar* la obra 1 ⇒ se salta al nodo $(2,11)$ (línea gruesa hacia la derecha‑abajo).\n",
    "3. Repite el patrón para las obras 2, 3 y 4 → nodos verdes hasta $(5,1)$.\n",
    "4. Con 1 millón restante los costos ya no caben ⇒ la línea gruesa va horizontal (saltos) de $(5,1)$ a $(6,1)$ y luego a $(7,1)$.\n",
    "5. $(7,1)$ no tiene hijos: fin del recorrido y del episodio.\n",
    "\n",
    "**Lectura rápida**\n",
    "\n",
    "* **Obras construidas**: 1, 2, 3, 4 (cada vez que la flecha baja es un “tomar”).\n",
    "* **Obras saltadas**: 5, 6 (flechas horizontales).\n",
    "* **Empleos logrados**: 31 000 (coincide con el valor calculado).\n",
    "* **Dinero sobrante**: 1 millón (por eso el nodo final sigue teniendo $b{=}1$).\n",
    "\n",
    "**Para qué sirven los nodos grises**\n",
    "\n",
    "Aunque la política voraz no los visite, ayudan a visualizar cómo *podría* evolucionar el sistema si en algún momento tomáramos decisiones distintas (por ejemplo, saltar la obra 3 o arrancar con otro presupuesto). Así el grafo muestra todo el espacio de posibilidades mientras la línea negra ilustra la única secuencia elegida por la política.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"assets/policy_evaluation_dag.png\" alt=\"Policy Evaluation DAG\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3cc19",
   "metadata": {},
   "source": [
    "## Policy Iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166049b3",
   "metadata": {},
   "source": [
    "```text\n",
    "# Alterna evaluación y mejora hasta que la política se estabiliza\n",
    "# Entradas:\n",
    "#   S, A(s), p(s',r|s,a), γ, θ\n",
    "# Salidas:\n",
    "#   π*  : política óptima\n",
    "#   V*  : función de valor óptima\n",
    "# -------------------------------------------\n",
    "\n",
    "# 1. Inicialización\n",
    "π(s) ← acción cualquiera  para todo s ∈ S\n",
    "V(s) ← 0\n",
    "\n",
    "bucle:\n",
    "    # 2. Evaluar la política actual π  (igual que el bloque anterior)\n",
    "    repetir\n",
    "        Δ ← 0\n",
    "        para cada s ∈ S:\n",
    "            v ← V(s)\n",
    "            a ← π(s)\n",
    "            V(s) ← Σ_{s',r} p(s',r | s,a) · [ r + γ · V(s') ]\n",
    "            Δ ← max(Δ, |v − V(s)|)\n",
    "    hasta que Δ < θ\n",
    "\n",
    "    # 3. Mejorar la política\n",
    "    policy_stable ← true\n",
    "    para cada s ∈ S:\n",
    "        old ← π(s)\n",
    "        π(s) ← argmax_a Σ_{s',r} p(s',r | s,a) · [ r + γ · V(s') ]\n",
    "        si old ≠ π(s):\n",
    "            policy_stable ← false\n",
    "\n",
    "    si policy_stable:\n",
    "        break\n",
    "\n",
    "return π, V\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee9bc5",
   "metadata": {},
   "source": [
    "### Pseudocódigo\n",
    "\n",
    "El siguiente algoritmo encuentra una política óptima en un problema de decisión resolviendo iterativamente dos etapas: **evaluación de política** y **mejora de política**. La política y la función de valor se actualizan hasta que la política deje de cambiar.\n",
    "\n",
    "##### Entradas\n",
    "- $\\mathcal{S}$: conjunto de estados\n",
    "- $\\mathcal{A}(s)$: conjunto de acciones disponibles en cada estado $s$\n",
    "- $p(s', r \\mid s, a)$: probabilidad de transición y recompensa\n",
    "- $\\gamma$: factor de descuento\n",
    "- $\\theta$: umbral de convergencia para la evaluación de política\n",
    "\n",
    "##### 1. Inicialización\n",
    "Asignar de manera arbitraria:\n",
    "- Una política inicial $\\pi(s) \\in \\mathcal{A}(s)$  \n",
    "- Una función de valor $V(s) \\in \\mathbb{R}$ para todo $s \\in \\mathcal{S}$\n",
    "\n",
    "##### 2. Evaluación de la política\n",
    "Repetir hasta convergencia:\n",
    "\n",
    "1. Inicializar $\\Delta \\leftarrow 0$  \n",
    "2. Para cada estado $s \\in \\mathcal{S}$:  \n",
    "   - Guardar el valor actual: $v \\leftarrow V(s)$  \n",
    "   - Actualizar según la política actual:  \n",
    "     $$\n",
    "     V(s) \\leftarrow \\sum_{s', r} p(s', r \\mid s, \\pi(s)) \\left[ r + \\gamma V(s') \\right]\n",
    "     $$\n",
    "   - Actualizar el cambio máximo:  \n",
    "     $$\n",
    "     \\Delta \\leftarrow \\max(\\Delta,\\; |v - V(s)|)\n",
    "     $$\n",
    "\n",
    "Finalizar cuando $\\Delta < \\theta$\n",
    "\n",
    "##### 3. Mejora de la política\n",
    "1. Inicializar: $policy\\text{-}stable \\leftarrow \\text{true}$  \n",
    "2. Para cada estado $s \\in \\mathcal{S}$:  \n",
    "   - Almacenar la acción actual: $a \\leftarrow \\pi(s)$  \n",
    "   - Actualizar la política eligiendo la mejor acción según $V$:  \n",
    "     $$\n",
    "     \\pi(s) \\leftarrow \\arg\\max_a \\sum_{s', r} p(s', r \\mid s, a) \\left[ r + \\gamma V(s') \\right]\n",
    "     $$\n",
    "   - Si $a \\ne \\pi(s)$ entonces:  \n",
    "     $policy\\text{-}stable \\leftarrow \\text{false}$\n",
    "\n",
    "##### 4. Verificación de convergencia**\n",
    "- Si $policy\\text{-}stable$ es verdadero:  \n",
    "  Detener y retornar $(V, \\pi)$  \n",
    "- De lo contrario: volver a la etapa de evaluación de política (paso 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74c73b",
   "metadata": {},
   "source": [
    "### Ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b436e0",
   "metadata": {},
   "source": [
    "#### Iteración 1 — Evaluar π₀\n",
    "\n",
    "Para claridad solo barreremos *los estados que realmente aparecen* al ejecutar la política:\n",
    "\n",
    "| Paso | $s=(i,b)$ antes | Acción π₀ | Recompensa r | $s'$ después | Nuevo V(s)=r+V(s') |\n",
    "|-----|-----------------|-----------|-------------|--------------|--------------------|\n",
    "| 6 | (6,1) | skip | 0 | (7,1) | 0 |\n",
    "| 5 | (5,1) | skip | 0 | (6,1) | 0 |\n",
    "| 4 | (4,7) | take | 9 | (5,1) | 9+0 = 9 |\n",
    "| 3 | (3,8) | take | 3 | (4,7) | 3+9 = 12 |\n",
    "| 2 | (2,11)| take | 6 | (3,8) | 6+12 = 18 |\n",
    "| 1 | (1,20)| take | 13| (2,11)|13+18 = 31 |\n",
    "\n",
    "Resultado parcial: $V_{\\pi_0}(1,20)=31$  \n",
    "y así sucesivamente:\n",
    "$\n",
    "\\begin{aligned}\n",
    "V_{\\pi_0}(2,11)&=18,\\;\n",
    "V_{\\pi_0}(3,8)=12,\\;\n",
    "V_{\\pi_0}(4,7)=9,\\;\n",
    "V_{\\pi_0}(5,1)=0,\\;\n",
    "V_{\\pi_0}(6,1)=0.\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "#### Iteración 1 — Mejora con los valores de $V_{\\pi_0}$  \n",
    "\n",
    "**Qué hay que comparar:**\n",
    "\n",
    "Para cada estado $s=(i,b)$ se calculan dos números:\n",
    "\n",
    "* **Value (take)** = recompensa inmediata + valor futuro tras restar el costo  \n",
    "  $$take = e_i \\;+\\; V_{\\pi_0}\\bigl(i+1,\\; b-c_i\\bigr)$$\n",
    "\n",
    "* **Value (skip)** = valor futuro si solo se avanza sin gastar  \n",
    "  $$skip = V_{\\pi_0}\\bigl(i+1,\\; b\\bigr)$$\n",
    "\n",
    "* Luego se elige la acción con el valor más alto.  \n",
    "\n",
    "\n",
    "A continuación se muestran **todos** los estados accesibles desde $(1,20)$ bajo $\\pi_0$ y, donde hace falta, los estados “saltados” que no se visitaron pero son necesarios para la comparación.\n",
    "\n",
    "| Estado $s=(i,b)$ | Datos para “take” | Cálculo Value(take) | Datos para “skip” | Cálculo Value(skip) | Acción que maximiza |\n",
    "|------------------|-------------------|---------------------|-------------------|---------------------|---------------------|\n",
    "| (1,20) | $e_1=13$, sucesor $(2,11)$ con $V=18$ | $13+18 = 31$ | sucesor $(2,20)$ con $V=33$ | $33$ | **skip** ← cambia |\n",
    "| (2,11) | $e_2=6$, sucesor $(3,8)$ con $V=12$  | $6+12 = 18$ | sucesor $(3,11)$ con $V=17$ | $17$ | take (se queda igual) |\n",
    "| (2,20)\\* | $e_2=6$, sucesor $(3,17)$ con $V=27$ | $6+27 = 33$ | sucesor $(3,20)$ con $V=30$\\* | $30$ | take (se queda igual) |\n",
    "| (3,8) | … | ya calculado en evaluación | … | — | sin cambio |\n",
    "| (3,17)\\* | … | análogo | … | — | sin cambio |\n",
    "| (4,7) | … | análogo | … | — | sin cambio |\n",
    "| (5,1) | … | análogo | … | — | sin cambio |\n",
    "\n",
    "\\*Estados marcados con asterisco *no aparecían en la trayectoria de evaluación*, pero sus valores se obtienen aplicando la misma política voraz a partir de ellos (se requiere para completar la tabla de comparación). Secuencia usando la misma política desde $(2,20)$:\n",
    "\n",
    "$$\n",
    "(2,20)\\xrightarrow{+6}(3,17)\\xrightarrow{+3}(4,16)\\xrightarrow{+9}(5,10)\\xrightarrow{+15}(6,0)\\xrightarrow{+0}(7,0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "V_{\\pi_0}(2,20)=6+3+9+15\\,=\\,33.\n",
    "$$\n",
    "\n",
    "\n",
    "* **En (1,20):**  \n",
    "  * Tomar la obra 1 da 13 miles ahora y deja $(2,11)$ con valor 18 ⇒ 31.  \n",
    "  * Saltarla deja $(2,20)$ con valor 33 ⇒ 33.  \n",
    "  * **33 > 31** → conviene *saltar*.  \n",
    "  La política se actualiza a *skip* en este único caso.\n",
    "\n",
    "* **En (2,11):**  \n",
    "  * Tomar la obra 2 → 6 miles + V(3,8)=12 ⇒ 18.  \n",
    "  * Saltarla           → V(3,11)=17.  \n",
    "  * **18 > 17** → se mantiene *take*.\n",
    "\n",
    "* **En todos los demás estados** comparados los valores\n",
    "coinciden con lo que la política voraz ya hacía, así que no se modifica nada.\n",
    "\n",
    "**Resultado de la mejora:**  \n",
    "La nueva política $\\pi_1$ solo difiere de $\\pi_0$ en un punto:\n",
    "> *Si estás en la obra 1 con los 20 millones completos, mejor “salta” la obra 1.*\n",
    "En cualquier otro estado las acciones siguen siendo las mismas que en la política voraz.\n",
    "\n",
    "#### Iteración 2 — Evaluar π₁\n",
    "\n",
    "Ahora la trayectoria con 20 M es distinta:\n",
    "\n",
    "| Paso | $s$ | π₁ | r | $s'$ | V(s)=r+V(s') |\n",
    "|------|-----|----|---|------|--------------|\n",
    "| 6 | (6,0) | skip | 0 | (7,0) | 0 |\n",
    "| 5 | (5,10)| take |15 | (6,0) |15+0=15 |\n",
    "| 4 | (4,16)| take | 9 | (5,10)| 9+15=24|\n",
    "| 3 | (3,17)| take | 3 | (4,16)| 3+24=27|\n",
    "| 2 | (2,20)| take | 6 | (3,17)| 6+27=33|\n",
    "| 1 | (1,20)| skip | 0 | (2,20)| 0+33=33|\n",
    "\n",
    "$V_{\\pi_1}(1,20)=33$.\n",
    "\n",
    "#### Iteración 2 — Mejorar con $V_{\\pi_1}$\n",
    "\n",
    "Al recalcular value(take) vs value(skip) para **todos** los estados, ninguno supera la acción que ya elige π₁. $policy-stable$ se mantiene en $true$ → **convergencia**.\n",
    "\n",
    "\n",
    "#### Resultado final\n",
    "\n",
    "*Obras construidas desde (1,20)*: 2, 3, 4, 5  \n",
    "*Costo total*: 3 + 1 + 6 + 10 = 20 M  \n",
    "*Empleos logrados*: 6 + 3 + 9 + 15 = **33 000**\n",
    "\n",
    "Tabla‑resumen de acciones óptimas:\n",
    "\n",
    "| Estado | Acción óptima |\n",
    "|--------|---------------|\n",
    "| (1,20) | skip |\n",
    "| (2,20) | take |\n",
    "| (3,17) | take |\n",
    "| (4,16) | take |\n",
    "| (5,10) | take |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f46ef",
   "metadata": {},
   "source": [
    "### Análisis\n",
    "\n",
    "**Qué representa el tablero**\n",
    "\n",
    "* Mapa de calor de 7 filas × 21 columnas.  \n",
    "  * **Filas** (eje vertical): obra que se está evaluando, $i = 1, 2, \\dots, 7$.  \n",
    "  * **Columnas** (eje horizontal): dinero restante, $b = 0, 1, \\dots, 20$ millones.\n",
    "\n",
    "**Cómo leer los colores**\n",
    "\n",
    "* Cada cuadrito muestra el valor óptimo $V^{*}(s)$ (empleos en miles) si empiezas en ese estado $s = (i,b)$ y sigues la **política óptima**.  \n",
    "  * **Verde claro** → pocos empleos futuros.  \n",
    "  * **Verde oscuro** → muchos empleos futuros.\n",
    "\n",
    "**Los números dentro de cada celda**\n",
    "\n",
    "* Número impreso = $V^{*}(s)$ exacto.  \n",
    "* Ejemplo: $33$ en la esquina superior‑derecha significa *33 000 empleos* si arrancas en la obra 1 con 20 millones aplicando la política óptima.\n",
    "\n",
    "**La trayectoria roja con círculos**  (lo que ocurre desde $(1,20)$)\n",
    "\n",
    "1. Parte en $(1,\\,20)$ y **salta** la obra 1.  \n",
    "2. Llega a $(2,\\,20)$ y **toma** la obra 2 → $(3,\\,17)$.  \n",
    "3. **Toma** la obra 3 → $(4,\\,16)$.  \n",
    "4. **Toma** la obra 4 → $(5,\\,10)$.  \n",
    "5. **Toma** la obra 5 → $(6,\\,0)$.  \n",
    "6. Sin dinero para la obra 6, **salta** → $(7,\\,0)$ (terminal).\n",
    "\n",
    "**Resultado de la política óptima en esa trayectoria**\n",
    "\n",
    "* **Empleos logrados**: 33 000.  \n",
    "* **Obras construidas**: 2, 3, 4, 5.  \n",
    "* **Dinero gastado**: 20 millones (presupuesto completamente usado).\n",
    "\n",
    "**¿Por qué aparecen celdas no visitadas?**\n",
    "\n",
    "El algoritmo calcula $V^{*}(s)$ para **todos** los estados, incluso aquellos que la ruta óptima nunca pisa.  \n",
    "Así se sabe *cuánto valdría* empezar con otro dinero u otra obra sin cambiar de política.\n",
    "\n",
    "**Idea clave**\n",
    "\n",
    "El gráfico muestra:\n",
    "\n",
    "* La **ganancia máxima** en cada combinación obra‑presupuesto (según el color).  \n",
    "* El **camino óptimo** (línea roja) que usa el dinero de la forma más eficiente: saltar la obra 1 y construir 2‑5, elevando el resultado de 31 000 → 33 000 empleos sin exceder los 20 millones.\n",
    "\n",
    "<br>\n",
    "<img src=\"assets/policy_iteration_v.png\" alt=\"Policy Iteration V\" width=\"900\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675328a",
   "metadata": {},
   "source": [
    "**Qué muestra el diagrama**\n",
    "\n",
    "Es un grafo dirigido que contiene *todos* los estados posibles $(i,b)$ y *todas* las transiciones legales entre ellos.  \n",
    "Cada nodo es un estado; cada flecha indica cómo cambia el estado al decidir *tomar* o *saltar* la obra actual **siguiendo la política óptima** obtenida con iteración de políticas.\n",
    "\n",
    "**Cómo están acomodados los nodos**\n",
    "\n",
    "* Las columnas van de izquierda a derecha con el índice de obra $i$: primera columna $i{=}1$, segunda $i{=}2$ … hasta $i{=}7$.  \n",
    "* Dentro de cada columna los nodos se apilan por el presupuesto restante $b$; arriba está $b{=}20$ y abajo $b{=}0$.  \n",
    "* Moverse una columna a la derecha siempre significa “pasar a la siguiente obra”.\n",
    "\n",
    "**Colores de los nodos**\n",
    "\n",
    "* **Verde** = estados por los que realmente pasa la política cuando **toma** las obras 2 – 5.  \n",
    "* **Azul** = estados donde la política **salta** (la obra 1 al inicio y la obra 6 cuando ya no queda dinero).  \n",
    "* **Gris claro** = todos los demás estados teóricos que existen pero la política óptima nunca toca.\n",
    "\n",
    "**Grosor de las flechas**\n",
    "\n",
    "* Flechas finas = *todas* las transiciones posibles según las reglas del problema.  \n",
    "* Línea negra gruesa = ruta exacta seguida desde el estado inicial $(1,20)$ hasta el final $(7,0)$.\n",
    "\n",
    "**Cómo leer la ruta resaltada**\n",
    "\n",
    "1. Arranca en el nodo azul superior de la primera columna $(1,20)$ y **salta** la obra 1 → flecha horizontal hasta $(2,20)$.  \n",
    "2. A partir de ahí **toma** las obras 2, 3, 4 y 5: nodos verdes $(2,20)\\!\\to\\!(3,17)\\!\\to\\!(4,16)\\!\\to\\!(5,10)$.  \n",
    "3. Con presupuesto $0$, la obra 6 ya no cabe → flecha horizontal (salto) a $(7,0)$.  \n",
    "4. $(7,0)$ no tiene hijos: fin del episodio.\n",
    "\n",
    "**Lectura rápida**\n",
    "\n",
    "* **Obras construidas**: 2, 3, 4, 5.  \n",
    "* **Obras saltadas**: 1, 6.  \n",
    "* **Empleos logrados**: 33 000 (6 + 3 + 9 + 15).  \n",
    "* **Dinero sobrante**: 0 millones (se usa todo el presupuesto).\n",
    "\n",
    "**Para qué sirven los nodos grises**\n",
    "\n",
    "Aunque la trayectoria óptima no los visite, ilustran cómo *podría* moverse el sistema con decisiones distintas (p. ej. saltar la obra 3 o empezar con otro presupuesto).  \n",
    "El grafo muestra todo el espacio de posibilidades mientras la línea negra señala la secuencia elegida por la política óptima.\n",
    "\n",
    "<br>\n",
    "<img src=\"assets/policy_iteration_dag.png\" alt=\"Policy Iteration DAG\" width=\"1000\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b59b9f",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c36073",
   "metadata": {},
   "source": [
    "### Pseudocódigo\n",
    "\n",
    "Este algoritmo aproxima de manera iterativa la función de valor óptima $V^*$ resolviendo la ecuación de Bellman de forma sucesiva. Una vez que la función de valor ha convergido, se extrae una política óptima $\\pi^*$ de forma determinista.\n",
    "\n",
    "##### Entradas\n",
    "- $\\mathcal{S}$: conjunto de estados\n",
    "- $\\mathcal{A}(s)$: conjunto de acciones disponibles en cada estado $s$\n",
    "- $p(s', r \\mid s, a)$: probabilidad de transición y recompensa al aplicar $a$ en $s$\n",
    "- $\\gamma$: factor de descuento ($0 \\leq \\gamma < 1$)\n",
    "- $\\theta$: umbral de convergencia\n",
    "\n",
    "##### 1. Inicialización\n",
    "Asignar arbitrariamente valores iniciales a la función $V$  \n",
    "(por ejemplo: $V(s) = 0$ para todo $s \\in \\mathcal{S}$)\n",
    "\n",
    "##### 2. Iteración de Bellman\n",
    "Repetir:\n",
    "\n",
    "1. Inicializar $\\Delta \\leftarrow 0$  \n",
    "2. Para cada estado $s \\in \\mathcal{S}$:\n",
    "   - Guardar el valor actual: $v \\leftarrow V(s)$  \n",
    "   - Actualizar el valor de $s$ usando la mejor acción posible:  \n",
    "     $$\n",
    "     V(s) \\leftarrow \\max_a \\sum_{s', r} p(s', r \\mid s, a) \\left[ r + \\gamma V(s') \\right]\n",
    "     $$\n",
    "   - Actualizar la diferencia máxima:  \n",
    "     $$\n",
    "     \\Delta \\leftarrow \\max\\left( \\Delta,\\; |v - V(s)| \\right)\n",
    "     $$\n",
    "\n",
    "Repetir hasta que $\\Delta < \\theta$\n",
    "\n",
    "##### 3. Extracción de la política\n",
    "Una vez que $V$ ha convergido, definir una política determinista $\\pi$ como:\n",
    "$$\n",
    "\\pi(s) = \\arg\\max_a \\sum_{s', r} p(s', r \\mid s, a) \\left[ r + \\gamma V(s') \\right]\n",
    "$$\n",
    "\n",
    "##### Salida\n",
    "- La función de valor $V$ aproximada  \n",
    "- Una política determinista $\\pi$ que es óptima con respecto a $V$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c178eaf",
   "metadata": {},
   "source": [
    "### Ejecusción\n",
    "\n",
    "#### Inicialización\n",
    "\n",
    "$V_0(i,b)=0\\qquad\\forall\\,i\\in\\{1,\\dots,7\\},\\;b\\in\\{0,\\dots,20\\}.$\n",
    "* Ejemplos concretos: $V_0(1,20)=0,\\;V_0(2,11)=0,\\;V_0(6,0)=0$.\n",
    "\n",
    "#### Iteración 1\n",
    "\n",
    "Para cada estado se calcula **dos posibles valores** —uno por la acción *take* y otro por la acción *skip*— y se elige el mayor.\n",
    "\n",
    "$$\n",
    "V_1(i,b) \\;=\\; \\max\\!\\Bigl\\{\\,\\underbrace{e_i + V_0\\bigl(i\\!+\\!1,\\;b-c_i\\bigr)}_{\\text{valor\\_take}},\\;\n",
    "\\underbrace{V_0\\bigl(i\\!+\\!1,\\,b\\bigr)}_{\\text{valor\\_skip}}\\Bigr\\}\n",
    "$$\n",
    "\n",
    "**Significado de cada término**\n",
    "\n",
    "* $e_i$  — empleos (en miles) que genera la obra actual \\(i\\) si se construye.  \n",
    "* $c_i$  — costo (en millones) de esa obra.  \n",
    "* \\(b\\)  — presupuesto que queda antes de decidir.  \n",
    "* $(i+1,\\;b-c_i)$  — estado sucesor si se **toma** la obra.  \n",
    "* $(i+1,\\,b)$  — estado sucesor si se **salta** la obra.  \n",
    "\n",
    "1. **Comprueba si la obra cabe**:  \n",
    "   *Si* \\(c_i \\le b\\) → la acción *take* es factible; calcula ambas expresiones.  \n",
    "   *Si* \\(c_i > b\\) → la obra no cabe; descarta la opción *take*.\n",
    "\n",
    "2. **Calcula los dos valores**  \n",
    "\n",
    "3. **Elige el máximo**  \n",
    "   $$V_1(i,b) = \\max\\{\\,\\text{valor\\_take},\\,\\text{valor\\_skip}\\,\\}$$\n",
    "\n",
    "> Nota: En la primera iteración $V_0(\\cdot)=0$, así que\n",
    "> *valor\\_take* se reduce a \\(e_i\\) y *valor\\_skip* se reduce a \\(0\\).  \n",
    "\n",
    "Eso explica por qué, la primera vez, \\(V_1\\) simplemente copia los empleos inmediatos de cada acción factible. Es decir, como $V_0\\equiv0$, sólo cuenta la recompensa inmediata:\n",
    "\n",
    "| Estado $s$ | take ($e_i$) | skip | $V_1(s)$ |\n",
    "|------------|-------------|------|----------|\n",
    "| $(5,10)$ | $15$ | $0$ | **15** |\n",
    "| $(4,16)$ | $9$  | $0$ | **9** |\n",
    "| $(3,17)$ | $3$  | $0$ | **3** |\n",
    "| $(2,20)$ | $6$  | $0$ | **6** |\n",
    "| $(1,20)$ | $13$ | $0$ | **13** |\n",
    "\n",
    "(Demás combinaciones se quedan en $0$).  \n",
    "Δ (máx. cambio) = 15\n",
    "\n",
    "#### Iteración 2  (con $V_1$ como base)\n",
    "\n",
    "| Estado $s$ | Sucesor take | Sucesor skip | take (eₙ + V₁) | skip (V₁) | V₂(s) |\n",
    "|------------|-------------|--------------|---------------|-----------|-------|\n",
    "| (5,10) | (6,0)  | (6,10) | 15 + 0  | 0  | **15** |\n",
    "| (4,16) | (5,10) | (5,16) | 9 + 15  | 15 | **24** |\n",
    "| (3,17) | (4,16) | (4,17) | 3 + 9   | 9  | **12** |\n",
    "| (2,20) | (3,17) | (3,20) | 6 + 3   | 3  | **9**  |\n",
    "| (1,20) | (2,11) | (2,20) | 13 + 6  | 9  | **19** |\n",
    "\n",
    "Δ = 15 (el mayor salto fue de 9 → 24).\n",
    "\n",
    "**Interpretación de los sucesores**\n",
    "\n",
    "* **Sucesor take** = $(i+1,\\;b-c_i)$ — el índice de obra avanza y se descuenta el costo.  \n",
    "* **Sucesor skip** = $(i+1,\\;b)$ — solo avanza el índice; el presupuesto no cambia.  \n",
    "\n",
    "#### Iteración 3\n",
    "\n",
    "| Estado $s$ | Sucesor take | Sucesor skip | take (eₙ + V₂) | skip (V₂) | V₃(s) |\n",
    "|------------|-------------|--------------|---------------|-----------|-------|\n",
    "| (5,10) | (6,0)  | (6,10) | 15 + 0  | 0  | 15 |\n",
    "| (4,16) | (5,10) | (5,16) | 9 + 15 | 15 | 24 |\n",
    "| (3,17) | (4,16) | (4,17) | 3 + 24 | 24 | **27** |\n",
    "| (2,20) | (3,17) | (3,20) | 6 + 12 | 27 | **27** |\n",
    "| (1,20) | (2,11) | (2,20) | 13 + 6 | 27 | **27** |\n",
    "\n",
    "Δ = 8 (máx. cambio 19 → 27).\n",
    "\n",
    "#### Iteración 4\n",
    "\n",
    "| Estado $s$ | take (eₙ + V₃) | skip (V₃) | V₄(s) |\n",
    "|------------|---------------|-----------|-------|\n",
    "| (5,10) | 15 | 0   | 15 |\n",
    "| (4,16) | 24 | 15  | 24 |\n",
    "| (3,17) | 27 | 24  | 27 |\n",
    "| (2,20) | 6 + 27 = **33** | 27 | 33 |\n",
    "| (1,20) | 13 + 18 = 31 | 33 | **33** |\n",
    "\n",
    "No cambia ningún número relevante ⇒ Δ = 0 < θ  \n",
    "**Convergencia tras cuatro barridos** (0 → 1 → 2 → 3 → 4).\n",
    "\n",
    "Valores relevantes:\n",
    "\n",
    "$$\n",
    "V^{*}(1,20)=33,\\;\n",
    "V^{*}(2,20)=33,\\;\n",
    "V^{*}(3,17)=27,\\;\n",
    "V^{*}(4,16)=24,\\;\n",
    "V^{*}(5,10)=15,\\;\n",
    "V^{*}(6,0)=0.\n",
    "$$\n",
    "\n",
    "#### Derivación de la política óptima \n",
    "\n",
    "Para cada estado se comparan:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q(s,\\text{take}) &= e_i + V^{*}(i+1,\\,b-c_i),\\\\\n",
    "Q(s,\\text{skip}) &= V^{*}(i+1,b).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "| Estado | $Q_{\\text{take}}$ | $Q_{\\text{skip}}$ | Acción óptima |\n",
    "|--------|------------------|-------------------|---------------|\n",
    "| $(1,20)$ | $31$ | $33$ | **skip** |\n",
    "| $(2,20)$ | $33$ | $27$ | **take** |\n",
    "| $(3,17)$ | $27$ | $24$ | **take** |\n",
    "| $(4,16)$ | $24$ | $15$ | **take** |\n",
    "| $(5,10)$ | $15$ | $0$  | **take** |\n",
    "| $(6,0)$  | $0$  | $0$  | skip |\n",
    "\n",
    "Regla final: *take si $c_i\\le b$, skip si no;* excepto en $(1,20)$ donde se garantiza **skip** para saltar la obra 1.\n",
    "\n",
    "#### Resultado global\n",
    "\n",
    "| Métrica | Valor |\n",
    "|---------|-------|\n",
    "| Obras construidas | 2, 3, 4, 5 |\n",
    "| Costo total | 3+1+6+10 = 20 M |\n",
    "| Empleos logrados | 6+3+9+15 = 33,000) |\n",
    "| Iteraciones (Δ < θ) | 4 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
